{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xor():\n",
    "    def __init__(self,n): \n",
    "        # n is the number of neurons in the hidden layer\n",
    "        self.layers_Z={1:[] , 2:[]}\n",
    "        self.layers_A={0:[], 1:[] , 2:[]}\n",
    "        self.weights={1:[[rd.uniform(-1, 1) for i in range(2)] for j in range(n)], \n",
    "                     2:[rd.uniform(-1, 1) for i in range(n)]}\n",
    "        self.b= {1: [[0],[0]] , 2:[0]}\n",
    "        self.activation= \"relu\"\n",
    "        self.loss=[]  # plot this loss afterwards\n",
    "        \n",
    "    def affineForward(self,x, w, b):\n",
    "        return np.dot(self.weights[w],x) + self.b[b]\n",
    "\n",
    "    \n",
    "    def activationForward(self, A):\n",
    "\n",
    "\n",
    "        if self.activation == \"sig\":\n",
    "            A = self.sigmoid(A)\n",
    "        elif self.activation == \"relu\":\n",
    "            A = self.relu(A)\n",
    "        return A\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        x = X.copy()\n",
    "        out = 1/(1 + np.exp(-x))\n",
    "        return out\n",
    "    \n",
    "    def relu(self, X):\n",
    "        activation = np.maximum(0,X)\n",
    "        return activation\n",
    "    \n",
    "    def lossfunction(self, y_hat, y ):\n",
    "        print(\"print\")\n",
    "        print sum((y_hat-y)**2)\n",
    "        loss = 1/2*sum((y_hat-y)**2)\n",
    "\n",
    "        \n",
    "        dAL = y_hat - y\n",
    "        return loss, dAL\n",
    "            \n",
    "        \n",
    "    \n",
    "    def forward_prop(self,data):\n",
    "#         inp= [[0, 1],[1,1]]\n",
    "#         out=out\n",
    "        self.layers_A[0]= data\n",
    "        self.layers_Z[1]= self.affineForward(self.layers_A[0],1,1)\n",
    "        self.layers_A[1]= self.activationForward(self.layers_Z[1])\n",
    "        self.layers_Z[2]= self.affineForward(self.layers_A[1],2,2)\n",
    "        self.layers_A[2]=self.activationForward(self.layers_Z[2])\n",
    "        return self.layers_A[2]\n",
    "    \n",
    "    def background_prop(self, target, alpha):\n",
    "        loss, dA_2= self.lossfunction(self.layers_A[2],target)\n",
    "        self.loss.append(loss)\n",
    "        print(\" loss is \"+ str(loss))\n",
    "        gZ_2= self.G_Z(self.layers_Z[2])\n",
    "        dZ_2= dA_2 * gZ_2\n",
    "\n",
    "        dA_1= np.dot(np.matrix(self.weights[2]).T, np.matrix(dZ_2))\n",
    "        \n",
    "        dW_2= np.dot(np.matrix(dZ_2), np.matrix(self.layers_A[1]).T)\n",
    "        dW_2= np.array(dW_2)[0]\n",
    "\n",
    "        gZ_1= self.G_Z(self.layers_Z[1],)\n",
    "        \n",
    "        dZ_1= np.array(dA_1) * np.array(gZ_1)\n",
    "        \n",
    "        dA_0= np.dot(np.matrix(self.weights[1]).T, np.matrix(dZ_1))\n",
    "        \n",
    "        \n",
    "        dW_1= np.dot(np.matrix(dZ_1), np.matrix(self.layers_A[0]).T)\n",
    "        dW_1= np.array(dW_1)\n",
    "\n",
    "        \n",
    "#         print(alpha * dW_2)\n",
    "#         print(alpha * dW_1)\n",
    "        # update weights\n",
    "        self.weights[2] = self.weights[2] - alpha * dW_2\n",
    "        self.weights[1] = self.weights[1] - alpha * dW_1\n",
    "        \n",
    "        return 1\n",
    "        \n",
    "    def G_Z(self, Z):\n",
    "        x = Z.copy()\n",
    "        if self.activation == \"sig\":\n",
    "            out = np.exp(-x)/((1 + np.exp(-x))**2)\n",
    "        elif self.activation == \"relu\":\n",
    "            out = x * 1 * (x > 0)\n",
    "        return out        \n",
    "        \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def train(self, data, out,alpha):\n",
    "        for i in range(10):\n",
    "            print(\"pass \"+ str(i))\n",
    "            \n",
    "            self.forward_prop(data)       \n",
    "            self.background_prop(out, alpha)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[0,1,1,0]\n",
    "inp= [[0,0,1,1],[0,1,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 0\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 1\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 2\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 3\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 4\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 5\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 6\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 7\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 8\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n",
      "pass 9\n",
      "print\n",
      "1.0\n",
      " loss is 0.0\n"
     ]
    }
   ],
   "source": [
    "out=[1,0]\n",
    "inp= [[0,1],[1,1]]\n",
    "nn= xor(2)\n",
    "# nn.forward_prop(inp, out)\n",
    "nn.train(inp,out,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 0\n",
      "[0.         0.43717943]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 1\n",
      "[   0.         4910.78389955]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 2\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 3\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 4\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 5\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 6\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 7\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 8\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n",
      "pass 9\n",
      "[0. 0.]\n",
      "[1, 1]\n",
      " loss is 0.0\n"
     ]
    }
   ],
   "source": [
    "out=[1,1]\n",
    "inp= [[0,1],[1,0]]\n",
    "nn.train(inp,out,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weigths: layer 0 and 1\n",
      "[[-1.24858902 -0.76986153]\n",
      " [13.00405634 16.90627723]]\n",
      "weigths: layer 1 and 2\n",
      "[-0.02065439  8.3389418 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"weigths: layer 0 and 1\")\n",
    "print(nn.weights[1])\n",
    "print(\"weigths: layer 1 and 2\")\n",
    "print(nn.weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input data( shape 2*1 ) to calculate answer\n",
    "inp=[[0],[0]]\n",
    "nn.forward_prop(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numHideenNeuron= 10\n",
    "n= numHideenNeuron\n",
    "nn= xor(n)\n",
    "# x, y, learning_rate\n",
    "nn.train(inp,out,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: For backpropagation, I am using the method from Prof. Iddo notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
